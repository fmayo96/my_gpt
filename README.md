# MyGPT
## A transformer and tokenizer built from scratch using PyTorch, for eduational purposes.

In order to generate text clone the repository and run my_gpt.py. It defaults to cuda if available, if not it can be set to use mps (Apple Silicon by uncomenting the corresponding line)
